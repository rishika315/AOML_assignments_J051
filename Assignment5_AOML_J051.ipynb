{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "goal is to classify SMS messages as spam or ham (not spam) using different text-processing techniques and machine learning models."
      ],
      "metadata": {
        "id": "YqWcNY0nqaqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWmBdv1VnqUf",
        "outputId": "83a50ff8-e21c-4ac1-9e5d-f11f0fc1d6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/uciml/sms-spam-collection-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 211k/211k [00:00<00:00, 66.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"uciml/sms-spam-collection-dataset\")\n",
        "df = pd.read_csv(path + \"/spam.csv\", encoding=\"latin-1\")[[\"v1\", \"v2\"]]  # Keep relevant columns\n",
        "df.columns = [\"label\", \"text\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numeric\n",
        "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "# Text Cleaning Function\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "0qHTNek0oSEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
        "X_train_clean, X_test_clean, _, _ = train_test_split(df[\"clean_text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Extraction - BOW & TF-IDF\n",
        "vectorizers = {\n",
        "    \"BOW\": CountVectorizer(),\n",
        "    \"TF-IDF\": TfidfVectorizer()\n",
        "}\n",
        "\n",
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "bquVYGTCoWMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main idea is to create a vocabulary from all documents and represent each document as a vector based on word occurrences.\n",
        "Variants include binary BoW (presence/absence of words) and frequency-based BoW (counting occurrences)."
      ],
      "metadata": {
        "id": "Mv0kYYnSooh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Evaluation\n",
        "for vec_name, vectorizer in vectorizers.items():\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    X_train_clean_vec = vectorizer.fit_transform(X_train_clean)\n",
        "    X_test_clean_vec = vectorizer.transform(X_test_clean)\n",
        "\n",
        "    print(f\"\\n--- {vec_name} Features ---\")\n",
        "    for model_name, model in models.items():\n",
        "        # Train on raw text\n",
        "        model.fit(X_train_vec, y_train)\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "        acc_raw = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Train on cleaned text\n",
        "        model.fit(X_train_clean_vec, y_train)\n",
        "        y_pred_clean = model.predict(X_test_clean_vec)\n",
        "        acc_clean = accuracy_score(y_test, y_pred_clean)\n",
        "\n",
        "        print(f\"{model_name}: Raw Accuracy: {acc_raw:.4f} | Cleaned Accuracy: {acc_clean:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_AdDcXooYmP",
        "outputId": "8c80b2f8-472a-4b0d-f610-49a248b8dc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BOW Features ---\n",
            "Naive Bayes: Raw Accuracy: 0.9839 | Cleaned Accuracy: 0.9794\n",
            "Random Forest: Raw Accuracy: 0.9758 | Cleaned Accuracy: 0.9722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:15:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:15:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost: Raw Accuracy: 0.9776 | Cleaned Accuracy: 0.9776\n",
            "\n",
            "--- TF-IDF Features ---\n",
            "Naive Bayes: Raw Accuracy: 0.9623 | Cleaned Accuracy: 0.9516\n",
            "Random Forest: Raw Accuracy: 0.9749 | Cleaned Accuracy: 0.9731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:15:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:15:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost: Raw Accuracy: 0.9767 | Cleaned Accuracy: 0.9812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create a voting classifier\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('nb', MultinomialNB()),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "        ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"))\n",
        "    ],\n",
        "    voting='hard'  # 'hard' for majority vote, 'soft' for probability averaging\n",
        ")\n",
        "\n",
        "# Train on TF-IDF features\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "ensemble_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_ensemble = ensemble_model.predict(X_test_tfidf)\n",
        "\n",
        "# Accuracy\n",
        "acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
        "print(f\"\\nEnsemble Model Accuracy (TF-IDF): {acc_ensemble:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc6_XTESpLRP",
        "outputId": "d2cc05e7-6fec-4dc7-c6bd-3b34ce984595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:19:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble Model Accuracy (TF-IDF): 0.9749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In text tasks, it's used for sentiment intensity, review score predictions, or text-based regression problems."
      ],
      "metadata": {
        "id": "E1yMRfI7ptQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample messages\n",
        "test_messages = [\n",
        "    \"Congratulations! You've won a free lottery ticket! Click here to claim now!\",  # Likely spam\n",
        "    \"Hey, are we still meeting for coffee at 5?\",  # Likely ham\n",
        "    \"URGENT! Your bank account is compromised. Call this number immediately!\",  # Likely spam\n",
        "    \"See you at the gym later. Bring your workout shoes!\",  # Likely ham\n",
        "]\n",
        "\n",
        "# Convert to TF-IDF format\n",
        "test_vectors = vectorizer.transform(test_messages)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_vectors)\n",
        "\n",
        "# Display results\n",
        "for msg, pred in zip(test_messages, predictions):\n",
        "    print(f\"Message: {msg} --> Prediction: {'Spam' if pred == 1 else 'Ham'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfr5G1Enq9yQ",
        "outputId": "e91bddc3-2bb6-4e50-b639-8be114214fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: Congratulations! You've won a free lottery ticket! Click here to claim now! --> Prediction: Spam\n",
            "Message: Hey, are we still meeting for coffee at 5? --> Prediction: Ham\n",
            "Message: URGENT! Your bank account is compromised. Call this number immediately! --> Prediction: Spam\n",
            "Message: See you at the gym later. Bring your workout shoes! --> Prediction: Ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X_train_tfidf, y_train, cv=5)\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n"
      ],
      "metadata": {
        "id": "VvbpouqorEYv",
        "outputId": "2f927665-533a-41fe-8c7b-8c6edb1f19fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:26:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:26:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:26:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:26:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:26:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.97869955 0.97982063 0.97979798 0.97530864 0.98316498]\n",
            "Mean CV Score: 0.9793583568620938\n"
          ]
        }
      ]
    }
  ]
}